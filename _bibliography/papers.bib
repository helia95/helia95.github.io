---
---
@misc{goel2023pairdiffusion,
      title={PAIR-Diffusion: Object-Level Image Editing with Structure-and-Appearance Paired Diffusion Models},
      author={Vidit Goel* and Elia Peruzzo* and Yifan Jiang and Dejia Xu and Nicu Sebe and Trevor Darrell and Zhangyang Wang and Humphrey Shi},
      year={2023},
      arxiv={2303.17546},
      selected={true},
      abbr={arxiv},
      bibtex_show={true},
      code={https://github.com/Picsart-AI-Research/PAIR-Diffusion},
      dimensions={ture},
      abstract={Image editing using diffusion models has witnessed extremely fast-paced growth recently. There are various ways in which previous works enable controlling and editing images. Some works use high-level conditioning such as text, while others use low-level conditioning. Nevertheless, most of them lack fine-grained control over the properties of the different objects present in the image, i.e. object-level image editing. In this work, we consider an image as a composition of multiple objects, each defined by various properties. Out of these properties, we identify structure and appearance as the most intuitive to understand and useful for editing purposes. We propose Structure-and-Appearance Paired Diffusion model (PAIR-Diffusion), which is trained using structure and appearance information explicitly extracted from the images. The proposed model enables users to inject a reference image's appearance into the input image at both the object and global levels. Additionally, PAIR-Diffusion allows editing the structure while maintaining the style of individual components of the image unchanged. We extensively evaluate our method on LSUN datasets and the CelebA-HQ face dataset, and we demonstrate fine-grained control over both structure and appearance at the object level. We also applied the method to Stable Diffusion to edit any real image at the object level.}

}

@article{peruzzo2023interactive,
  title={Interactive Neural Painting},
  author={Peruzzo, Elia and Menapace, Willi and Goel, Vidit and Arrigoni, Federica and Tang, Hao and Xu, Xingqian and Chopikyan, Arman and Orlov, Nikita and Hu, Yuxiao and Shi, Humphrey and others},
  journal={Computer Vision and Image Understanding},
  volume={235},
  pages={103778},
  year={2023},
  abbr={arxiv},
  bibtex_show={true},
  code={https://github.com/Picsart-AI-Research/PAIR-Diffusion},
  dimensions={ture},
  publisher={Elsevier}
}


@arXiv{https://doi.org/10.48550/arxiv.2206.04636,
  doi = {10.48550/ARXIV.2206.04636},
  url = {https://arxiv.org/abs/2206.04636},
  author = {Peruzzo, Elia and Sangineto, Enver and Liu, Yahui and De Nadai, Marco and Bi, Wei and Lepri, Bruno and Sebe, Nicu},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Spatial Entropy as an Inductive Bias for Vision Transformers},
  publisher = {arXiv},
  year = {2022},
  copyright = {arXiv.org perpetual, non-exclusive license},
  selected={true},
  abbr={arxiv},
  bibtex_show={true},
  abstract={Recent work has shown that the attention maps of Vision Transformers (VTs), when trained with self-supervision, can contain a semantic segmentation structure which does not spontaneously emerge when training is supervised. In this paper, we explicitly encourage the emergence of this spatial clustering as a form of training regularization, this way including a self-supervised pretext task into the standard supervised learning. In more detail, we propose a VT regularization method based on a spatial formulation of the information entropy. By minimizing the proposed spatial entropy, we explicitly ask the VT to produce spatially ordered attention maps, this way including an object-based prior during training. Using extensive experiments, we show that the proposed regularization approach is beneficial with different training scenarios, datasets, downstream tasks and VT architectures. The code will be available upon acceptance. },
  arxiv={2206.04636},
  code={https://github.com/helia95/SAR},
  dimensions={true},
}

@INPROCEEDINGS{https://doi.org/10.48550/arxiv.2206.04636,
    author= {Ayorinde, John O.O. and Citterio, Federica and Landrò, Matteo and Peruzzo, Elia and Islam, Tuba and Tilley, Simon and Taylor, Geoffrey and Bardsley, Victoria and Liò, Pietro and Samoshkin, Alex and Pettigrew, Gavin J.},
    title = {Artificial Intelligence You Can Trust: What Matters Beyond Performance When Applying Artificial Intelligence to Renal Histopathology?.},
    booktitle= {Journal of the American Society of Nephrology},
    pages={2133-2140},
    year={2022},
    abbr={JASN},
    bibtex_show={true},
    html={https://journals.lww.com/jasn/Abstract/2022/12000/Artificial_Intelligence_You_Can_Trust__What.5.aspx},
    bibtex_show={true},
    abstract={Although still in its infancy, artificial intelligence (AI) analysis of kidney biopsy images is anticipated to become an integral aspect of renal histopathology. As these systems are developed, the focus will understandably be on developing ever more accurate models, but successful translation to the clinic will also depend upon other characteristics of the system. In the extreme, deployment of highly performant but “black box” AI is fraught with risk, and high-profile errors could damage future trust in the technology. Furthermore, a major factor determining whether new systems are adopted in clinical settings is whether they are “trusted” by clinicians. Key to unlocking trust will be designing platforms optimized for intuitive human-AI interactions and ensuring that, where judgment is required to resolve ambiguous areas of assessment, the workings of the AI image classifier are understandable to the human observer. Therefore, determining the optimal design for AI systems depends on factors beyond performance, with considerations of goals, interpretability, and safety constraining many design and engineering choices. In this article, we explore challenges that arise in the application of AI to renal histopathology, and consider areas where choices around model architecture, training strategy, and workflow design may be influenced by factors beyond the final performance metrics of the system.}}

@INPROCEEDINGS{8953151,
  author={Peruzzo, Elia and Ding, Jian-Jiun},
  booktitle={IEEE Asia Pacific Conference on Circuits and Systems},
  title={Morphological Residue Encoding and Piecewise Approximation Techniques for Lossless Binary Image Compression},
  year={2019},
  pages={353-356},
  abbr={APCCAS},
  bibtex_show={true},}
